{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f753bb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input_data/30-07-2025 initial  05407709000120.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 184\u001b[39m\n\u001b[32m    181\u001b[39m         time.sleep(\u001b[32m21\u001b[39m)\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[43mlocalizar_dados_lucro_real\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m     remover_duplicatas_final()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 152\u001b[39m, in \u001b[36mlocalizar_dados_lucro_real\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlocalizar_dados_lucro_real\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     cnpjs = \u001b[43mler_cnpjs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mARQUIVO_ENTRADA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m     cnpjs_processados = ler_cnpjs_processados(ARQUIVO_SAIDA)\n\u001b[32m    154\u001b[39m     ultimo_checkpoint = carregar_checkpoint()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mler_cnpjs\u001b[39m\u001b[34m(caminho)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mler_cnpjs\u001b[39m(caminho):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaminho\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     cnpjs = df.iloc[:, \u001b[32m1\u001b[39m].tolist()\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [limpar_cnpj(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cnpjs]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/01- Rafa_&_21rfSoftwares/Rafa_Cnpjs/Analise-cnpjs-via-gov-buscando-dados-das-empresas-lucro-real/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/01- Rafa_&_21rfSoftwares/Rafa_Cnpjs/Analise-cnpjs-via-gov-buscando-dados-das-empresas-lucro-real/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/01- Rafa_&_21rfSoftwares/Rafa_Cnpjs/Analise-cnpjs-via-gov-buscando-dados-das-empresas-lucro-real/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/01- Rafa_&_21rfSoftwares/Rafa_Cnpjs/Analise-cnpjs-via-gov-buscando-dados-das-empresas-lucro-real/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/01- Rafa_&_21rfSoftwares/Rafa_Cnpjs/Analise-cnpjs-via-gov-buscando-dados-das-empresas-lucro-real/.venv/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'input_data/30-07-2025 initial  05407709000120.csv'"
     ]
    }
   ],
   "source": [
    "# consulta_cnpjs.py\n",
    "# Script Principal para consultar dados de CNPJs via API e salvar resultados em Excel\n",
    "# Autor: [21rfSoftwares]\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Caminhos dos arquivos ===\n",
    "ARQUIVO_ENTRADA = r'input_data/30-07-2025 initial  05407709000120.csv'\n",
    "ARQUIVO_SAIDA = r'output_data_cnae/ipynb_cnpj_limpos_.xlsx'\n",
    "CAMINHO_ERROS = r'Erros/cnpjs_python erros.py'\n",
    "CHECKPOINT_FILE = 'Checkpoint/checkpoint_erros.txt'\n",
    "\n",
    "def limpar_cnpj(cnpj):\n",
    "    cnpj_str = str(cnpj).zfill(14)\n",
    "    return ''.join(filter(str.isdigit, cnpj_str))\n",
    "\n",
    "def formatar_cnpj(cnpj):\n",
    "    cnpj = ''.join(filter(str.isdigit, str(cnpj)))\n",
    "    cnpj = cnpj.zfill(14)\n",
    "    return f'{cnpj[:2]}.{cnpj[2:5]}.{cnpj[5:8]}/{cnpj[8:12]}-{cnpj[12:]}'\n",
    "\n",
    "def ler_cnpjs(caminho):\n",
    "    df = pd.read_csv(caminho)\n",
    "    cnpjs = df.iloc[:, 1].tolist()\n",
    "    return [limpar_cnpj(c) for c in cnpjs]\n",
    "\n",
    "def ler_cnpjs_processados(caminho_saida):\n",
    "    if not os.path.exists(caminho_saida):\n",
    "        return set()\n",
    "    df = pd.read_excel(caminho_saida)\n",
    "    return set(df['cnpj'].astype(str).str.zfill(14))\n",
    "\n",
    "def registrar_erro_em_excel(cnpj, erro_msg):\n",
    "    df_erro = pd.DataFrame([{\n",
    "        'cnpj': formatar_cnpj(cnpj),\n",
    "        'data_hora': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'erro': erro_msg\n",
    "    }])\n",
    "    if os.path.exists(CAMINHO_ERROS):\n",
    "        df_existente = pd.read_excel(CAMINHO_ERROS)\n",
    "        df_completo = pd.concat([df_existente, df_erro], ignore_index=True)\n",
    "    else:\n",
    "        df_completo = df_erro\n",
    "    df_completo.to_excel(CAMINHO_ERROS, index=False)\n",
    "\n",
    "def consultar_cnpj(cnpj):\n",
    "    url = f'https://publica.cnpj.ws/cnpj/{cnpj}'\n",
    "    tentativas = 0\n",
    "    link_cnpj = f'https://cnpj.biz/{str(cnpj).zfill(14)}'\n",
    "\n",
    "    while tentativas < 3:\n",
    "        try:\n",
    "            response = requests.get(url, timeout=35)\n",
    "\n",
    "            if response.status_code == 404:\n",
    "                print(f'[404] CNPJ n√£o encontrado: {formatar_cnpj(cnpj)}')\n",
    "                registrar_erro_em_excel(cnpj, \"CNPJ n√£o encontrado (404)\")\n",
    "                break\n",
    "\n",
    "            if response.status_code == 429:\n",
    "                time.sleep(25)\n",
    "                tentativas += 1\n",
    "                continue\n",
    "\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            email_extraido = data.get('estabelecimento', {}).get('email', 'N/D')\n",
    "            email_formatado = 'e-mail n√£o cadastrado' if email_extraido in ['N/D', 'Erro', 'Timeout', '', None] else email_extraido\n",
    "\n",
    "            return {\n",
    "                'cnpj': formatar_cnpj(cnpj),\n",
    "                'nome': data.get('razao_social', 'N/D'),\n",
    "                'uf': data.get('estabelecimento', {}).get('estado', {}).get('sigla', 'N/D'),\n",
    "                'cidade': data.get('estabelecimento', {}).get('cidade', {}).get('nome', 'N/D'),\n",
    "                'email': email_formatado,\n",
    "                'link': link_cnpj,\n",
    "                'cnae_codigo': data.get('estabelecimento', {}).get('atividade_principal', {}).get('subclasse', 'N/D'),\n",
    "                'cnae_desc': data.get('estabelecimento', {}).get('atividade_principal', {}).get('descricao', 'N/D'),\n",
    "                'data_hora': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            }\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f'[ERRO] {formatar_cnpj(cnpj)} - {e}')\n",
    "            registrar_erro_em_excel(cnpj, str(e))\n",
    "            tentativas += 1\n",
    "            time.sleep(15)\n",
    "\n",
    "    print(f'[ERRO] Falha ap√≥s 3 tentativas: {formatar_cnpj(cnpj)}')\n",
    "    registrar_erro_em_excel(cnpj, \"Falha ap√≥s 3 tentativas ou erro desconhecido\")\n",
    "\n",
    "    return {\n",
    "        'cnpj': formatar_cnpj(cnpj),\n",
    "        'nome': 'Erro',\n",
    "        'uf': 'Erro',\n",
    "        'cidade': 'Erro',\n",
    "        'email': 'e-mail n√£o cadastrado',\n",
    "        'link': link_cnpj,\n",
    "        'cnae_codigo': 'Erro',\n",
    "        'cnae_desc': 'Erro',\n",
    "        'data_hora': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "\n",
    "def salvar_excel(lista_dados, caminho_saida):\n",
    "    df_novo = pd.DataFrame(lista_dados)\n",
    "    colunas_ordenadas = ['cnpj', 'nome', 'uf', 'cidade', 'email', 'link', 'cnae_codigo', 'cnae_desc', 'data_hora']\n",
    "    df_novo = df_novo[colunas_ordenadas]\n",
    "\n",
    "    if os.path.exists(caminho_saida):\n",
    "        df_existente = pd.read_excel(caminho_saida)\n",
    "        df_existente['cnpj'] = df_existente['cnpj'].astype(str).str.zfill(14)\n",
    "        df_existente = df_existente[colunas_ordenadas]\n",
    "        df_completo = pd.concat([df_existente, df_novo], ignore_index=True)\n",
    "    else:\n",
    "        df_completo = df_novo\n",
    "\n",
    "    df_completo.drop_duplicates(subset='cnpj', inplace=True)\n",
    "    df_completo.to_excel(caminho_saida, index=False)\n",
    "\n",
    "def salvar_checkpoint(cnpj):\n",
    "    with open(CHECKPOINT_FILE, 'w') as f:\n",
    "        f.write(cnpj)\n",
    "\n",
    "def carregar_checkpoint():\n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        with open(CHECKPOINT_FILE, 'r') as f:\n",
    "            return f.read().strip()\n",
    "    return None\n",
    "\n",
    "def remover_duplicatas_final():\n",
    "    caminho_entrada = ARQUIVO_SAIDA\n",
    "    caminho_saida = caminho_entrada.replace('.xlsx', '_sem_duplicatas.xlsx')\n",
    "    if not os.path.exists(caminho_entrada):\n",
    "        print(f'[ERRO] Arquivo {caminho_entrada} n√£o encontrado.')\n",
    "        return\n",
    "    try:\n",
    "        df = pd.read_excel(caminho_entrada)\n",
    "        df_sem_duplicatas = df.drop_duplicates(subset=[\n",
    "            'cnpj', 'nome', 'uf', 'cidade', 'email', 'link', 'cnae_codigo', 'cnae_desc'\n",
    "        ])\n",
    "        df_sem_duplicatas.to_excel(caminho_saida, index=False)\n",
    "        print(f'[OK] Duplicatas removidas. Resultado salvo em: {caminho_saida}')\n",
    "    except Exception as e:\n",
    "        print(f'[ERRO] Falha ao remover duplicatas: {e}')\n",
    "\n",
    "def localizar_dados_lucro_real():\n",
    "    cnpjs = ler_cnpjs(ARQUIVO_ENTRADA)\n",
    "    cnpjs_processados = ler_cnpjs_processados(ARQUIVO_SAIDA)\n",
    "    ultimo_checkpoint = carregar_checkpoint()\n",
    "\n",
    "    if ultimo_checkpoint:\n",
    "        try:\n",
    "            index_ultimo = cnpjs.index(ultimo_checkpoint)\n",
    "            cnpjs = cnpjs[index_ultimo + 1:]\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    novos_cnpjs = [c for c in cnpjs if c not in cnpjs_processados]\n",
    "    resultados = []\n",
    "    contador_para_remover_duplicatas = 0\n",
    "\n",
    "    for i, cnpj in enumerate(tqdm(novos_cnpjs, desc=\"Consultando CNPJs\", unit=\"cnpj\"), 1):\n",
    "        dados = consultar_cnpj(cnpj)\n",
    "        resultados.append(dados)\n",
    "        salvar_checkpoint(cnpj)\n",
    "        contador_para_remover_duplicatas += 1\n",
    "\n",
    "        if i % 5 == 0 or i == len(novos_cnpjs):\n",
    "            salvar_excel(resultados, ARQUIVO_SAIDA)\n",
    "            resultados = []\n",
    "\n",
    "        if contador_para_remover_duplicatas >= 10:\n",
    "            remover_duplicatas_final()\n",
    "            contador_para_remover_duplicatas = 0\n",
    "\n",
    "        time.sleep(21)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    localizar_dados_lucro_real()\n",
    "    remover_duplicatas_final()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92e4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificar erros e corrigir com novo busca na api\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "ARQUIVO_ENTRADA = r'resultado_consulta_cnae_II.xlsx'\n",
    "ARQUIVO_SAIDA = r'resultado_consulta_cnae_II_analisados.xlsx'\n",
    "CAMINHO_ERROS = r'/home/silva/1.1.1.1-Dados_Lucro_Real/Analise-cnpjs-via-gov-buscando-dados-das-empresas-lucro-real/erros_pos_revisao.xlsx'\n",
    "CHECKPOINT_FILE = 'checkpoint_erros.txt'\n",
    "\n",
    "def limpar_cnpj(cnpj):\n",
    "    cnpj_str = str(cnpj).zfill(14)\n",
    "    return ''.join(filter(str.isdigit, cnpj_str))\n",
    "\n",
    "def formatar_cnpj(cnpj):\n",
    "    cnpj = ''.join(filter(str.isdigit, str(cnpj)))\n",
    "    cnpj = cnpj.zfill(14)\n",
    "    return f'{cnpj[:2]}.{cnpj[2:5]}.{cnpj[5:8]}/{cnpj[8:12]}-{cnpj[12:]}'\n",
    "\n",
    "def ler_cnpjs(caminho):\n",
    "    df = pd.read_excel(caminho)\n",
    "    cnpjs = df.iloc[:, 1].tolist()\n",
    "    return [limpar_cnpj(c) for c in cnpjs]\n",
    "\n",
    "def ler_cnpjs_processados(caminho_saida):\n",
    "    if not os.path.exists(caminho_saida):\n",
    "        return set()\n",
    "    df = pd.read_excel(caminho_saida)\n",
    "    return set(df['cnpj'].astype(str).str.zfill(14))\n",
    "\n",
    "def registrar_erro_em_excel(cnpj, erro_msg):\n",
    "    df_erro = pd.DataFrame([{\n",
    "        'cnpj': formatar_cnpj(cnpj),\n",
    "        'data_hora': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'erro': erro_msg\n",
    "    }])\n",
    "    if os.path.exists(CAMINHO_ERROS):\n",
    "        df_existente = pd.read_excel(CAMINHO_ERROS)\n",
    "        df_completo = pd.concat([df_existente, df_erro], ignore_index=True)\n",
    "    else:\n",
    "        df_completo = df_erro\n",
    "    df_completo.to_excel(CAMINHO_ERROS, index=False)\n",
    "\n",
    "def consultar_cnpj(cnpj):\n",
    "    url = f'https://publica.cnpj.ws/cnpj/{cnpj}'\n",
    "    tentativas = 0\n",
    "    link_cnpj = f'https://cnpj.biz/{str(cnpj).zfill(14)}'\n",
    "    while tentativas < 3:\n",
    "        try:\n",
    "            response = requests.get(url, timeout=35)\n",
    "            if response.status_code == 404:\n",
    "                print(f'[404] CNPJ n√£o encontrado: {formatar_cnpj(cnpj)}')\n",
    "                registrar_erro_em_excel(cnpj, \"CNPJ n√£o encontrado (404)\")\n",
    "                break\n",
    "            if response.status_code == 429:\n",
    "                time.sleep(25)\n",
    "                tentativas += 1\n",
    "                continue\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            email_extraido = data.get('estabelecimento', {}).get('email', 'N/D')\n",
    "            email_formatado = 'e-mail n√£o cadastrado' if email_extraido in ['N/D', 'Erro', 'Timeout', '', None] else email_extraido\n",
    "            return {\n",
    "                'cnpj': formatar_cnpj(cnpj),\n",
    "                'nome': data.get('razao_social', 'N/D'),\n",
    "                'uf': data.get('estabelecimento', {}).get('estado', {}).get('sigla', 'N/D'),\n",
    "                'cidade': data.get('estabelecimento', {}).get('cidade', {}).get('nome', 'N/D'),\n",
    "                'email': email_formatado,\n",
    "                'link': link_cnpj,\n",
    "                'cnae_codigo': data.get('estabelecimento', {}).get('atividade_principal', {}).get('subclasse', 'N/D'),\n",
    "                'cnae_desc': data.get('estabelecimento', {}).get('atividade_principal', {}).get('descricao', 'N/D'),\n",
    "                'data_hora': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            }\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f'[ERRO] {formatar_cnpj(cnpj)} - {e}')\n",
    "            registrar_erro_em_excel(cnpj, str(e))\n",
    "            tentativas += 1\n",
    "            time.sleep(15)\n",
    "\n",
    "    print(f'[ERRO] Falha ap√≥s 3 tentativas: {formatar_cnpj(cnpj)}')\n",
    "    registrar_erro_em_excel(cnpj, \"Falha ap√≥s 3 tentativas ou erro desconhecido\")\n",
    "    return {\n",
    "        'cnpj': formatar_cnpj(cnpj),\n",
    "        'nome': 'Erro',\n",
    "        'uf': 'Erro',\n",
    "        'cidade': 'Erro',\n",
    "        'email': 'e-mail n√£o cadastrado',\n",
    "        'link': link_cnpj,\n",
    "        'cnae_codigo': 'Erro',\n",
    "        'cnae_desc': 'Erro',\n",
    "        'data_hora': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "\n",
    "def salvar_excel(lista_dados, caminho_saida):\n",
    "    df_novo = pd.DataFrame(lista_dados)\n",
    "    colunas_ordenadas = [\n",
    "        'cnpj', 'nome', 'uf', 'cidade', 'email',\n",
    "        'link', 'cnae_codigo', 'cnae_desc', 'data_hora'\n",
    "    ]\n",
    "    df_novo = df_novo[colunas_ordenadas]\n",
    "    if os.path.exists(caminho_saida):\n",
    "        df_existente = pd.read_excel(caminho_saida)\n",
    "        df_existente['cnpj'] = df_existente['cnpj'].astype(str).str.zfill(14)\n",
    "        df_existente = df_existente[colunas_ordenadas]\n",
    "        df_completo = pd.concat([df_existente, df_novo], ignore_index=True)\n",
    "    else:\n",
    "        df_completo = df_novo\n",
    "    df_completo.drop_duplicates(subset='cnpj', inplace=True)\n",
    "    df_completo.to_excel(caminho_saida, index=False)\n",
    "\n",
    "def salvar_checkpoint(cnpj):\n",
    "    with open(CHECKPOINT_FILE, 'w') as f:\n",
    "        f.write(cnpj)\n",
    "\n",
    "def carregar_checkpoint():\n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        with open(CHECKPOINT_FILE, 'r') as f:\n",
    "            return f.read().strip()\n",
    "    return None\n",
    "\n",
    "def remover_duplicatas_final():\n",
    "    caminho_entrada = ARQUIVO_SAIDA\n",
    "    caminho_saida = caminho_entrada.replace('.xlsx', '_sem_duplicatas.xlsx')\n",
    "    if not os.path.exists(caminho_entrada):\n",
    "        print(f'[ERRO] Arquivo {caminho_entrada} n√£o encontrado.')\n",
    "        return\n",
    "    try:\n",
    "        df = pd.read_excel(caminho_entrada)\n",
    "        df_sem_duplicatas = df.drop_duplicates(subset=[\n",
    "            'cnpj', 'nome', 'uf', 'cidade', 'email', 'link', 'cnae_codigo', 'cnae_desc'\n",
    "        ])\n",
    "        df_sem_duplicatas.to_excel(caminho_saida, index=False)\n",
    "        print(f'[OK] Duplicatas removidas. Resultado salvo em: {caminho_saida}')\n",
    "    except Exception as e:\n",
    "        print(f'[ERRO] Falha ao remover duplicatas: {e}')\n",
    "\n",
    "def localizar_dados_lucro_real():\n",
    "    cnpjs = ler_cnpjs(ARQUIVO_ENTRADA)\n",
    "    cnpjs_processados = ler_cnpjs_processados(ARQUIVO_SAIDA)\n",
    "    ultimo_checkpoint = carregar_checkpoint()\n",
    "\n",
    "    if ultimo_checkpoint:\n",
    "        try:\n",
    "            index_ultimo = cnpjs.index(ultimo_checkpoint)\n",
    "            cnpjs = cnpjs[index_ultimo + 1:]\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    novos_cnpjs = [c for c in cnpjs if c not in cnpjs_processados]\n",
    "    resultados = []\n",
    "    contador_para_remover_duplicatas = 0\n",
    "\n",
    "    for i, cnpj in enumerate(tqdm(novos_cnpjs, desc=\"Consultando CNPJs\", unit=\"cnpj\"), 1):\n",
    "        dados = consultar_cnpj(cnpj)\n",
    "        resultados.append(dados)\n",
    "        salvar_checkpoint(cnpj)\n",
    "        contador_para_remover_duplicatas += 1\n",
    "\n",
    "        if i % 5 == 0 or i == len(novos_cnpjs):\n",
    "            salvar_excel(resultados, ARQUIVO_SAIDA)\n",
    "            resultados = []\n",
    "\n",
    "        if contador_para_remover_duplicatas >= 10:\n",
    "            remover_duplicatas_final()\n",
    "            contador_para_remover_duplicatas = 0\n",
    "\n",
    "        time.sleep(21)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    localizar_dados_lucro_real()\n",
    "    remover_duplicatas_final()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b982852",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# tratamento manual arquivo cnae_II\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mformatar_cnpj\u001b[39m(cnpj_str):\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Formata CNPJ no padr√£o 00.000.000/0000-00.\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# tratamento manual arquivo cnae_II\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def formatar_cnpj(cnpj_str):\n",
    "    \"\"\"Formata CNPJ no padr√£o 00.000.000/0000-00.\"\"\"\n",
    "    cnpj_str = ''.join(filter(str.isdigit, str(cnpj_str))).zfill(14)\n",
    "    return f\"{cnpj_str[:2]}.{cnpj_str[2:5]}.{cnpj_str[5:8]}/{cnpj_str[8:12]}-{cnpj_str[12:]}\"\n",
    "\n",
    "\n",
    "def tratar_arquivo_excel(arquivo_entrada, arquivo_saida, colunas_referencia):\n",
    "    \"\"\"\n",
    "    Carrega um arquivo Excel, remove duplicatas com base em colunas v√°lidas,\n",
    "    formata o CNPJ e salva o resultado.\n",
    "    \"\"\"\n",
    "    # Carrega o Excel\n",
    "    df = pd.read_excel(arquivo_entrada)\n",
    "\n",
    "    # Verifica colunas dispon√≠veis e filtra as v√°lidas\n",
    "    colunas_disponiveis = df.columns.tolist()\n",
    "    colunas_validas = [col for col in colunas_referencia if col in colunas_disponiveis]\n",
    "\n",
    "    if not colunas_validas:\n",
    "        print(\"‚ö†Ô∏è Nenhuma das colunas especificadas existe no DataFrame.\")\n",
    "        return\n",
    "\n",
    "    # Remove duplicatas\n",
    "    df_sem_duplicados = df.drop_duplicates(subset=colunas_validas)\n",
    "\n",
    "    # Aplica a formata√ß√£o do CNPJ, se a coluna existir\n",
    "    if 'cnpj' in df_sem_duplicados.columns:\n",
    "        df_sem_duplicados['cnpj'] = df_sem_duplicados['cnpj'].apply(formatar_cnpj)\n",
    "\n",
    "    # Salva o resultado\n",
    "    df_sem_duplicados.to_excel(arquivo_saida, index=False)\n",
    "\n",
    "    # Feedback\n",
    "    print(f'‚úÖ {len(df) - len(df_sem_duplicados)} duplicatas removidas.')\n",
    "    print(f'üìÅ Arquivo salvo em: {arquivo_saida}')\n",
    "\n",
    "\n",
    "# ==== USO ====\n",
    "\n",
    "arquivo_entrada = r'resultado_consulta_cnae_II.xlsx'\n",
    "arquivo_saida = r'resposta_consulta_cnae_II_sem_duplicatas.xlsx'\n",
    "\n",
    "colunas_desejadas = ['cnpj', 'nome', 'razao_social', 'uf', 'cidade', 'email', 'link', 'cnae_codigo', 'cnae_desc']\n",
    "\n",
    "tratar_arquivo_excel(arquivo_entrada, arquivo_saida, colunas_desejadas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79210bdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# tratamento manual arquivo parciais838\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mformatar_cnpj\u001b[39m(cnpj_str):\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Formata CNPJ no padr√£o 00.000.000/0000-00.\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# tratamento manual arquivo parciais838\n",
    "!pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "def formatar_cnpj(cnpj_str):\n",
    "    \"\"\"Formata CNPJ no padr√£o 00.000.000/0000-00.\"\"\"\n",
    "    cnpj_str = ''.join(filter(str.isdigit, str(cnpj_str))).zfill(14)\n",
    "    return f\"{cnpj_str[:2]}.{cnpj_str[2:5]}.{cnpj_str[5:8]}/{cnpj_str[8:12]}-{cnpj_str[12:]}\"\n",
    "\n",
    "\n",
    "def tratar_arquivo_excel(arquivo_entrada, arquivo_saida, colunas_referencia):\n",
    "    \"\"\"\n",
    "    Carrega um arquivo Excel, remove duplicatas com base em colunas v√°lidas,\n",
    "    formata o CNPJ e salva o resultado.\n",
    "    \"\"\"\n",
    "    # Carrega o Excel\n",
    "    df = pd.read_excel(arquivo_entrada)\n",
    "\n",
    "    # Verifica colunas dispon√≠veis e filtra as v√°lidas\n",
    "    colunas_disponiveis = df.columns.tolist()\n",
    "    colunas_validas = [col for col in colunas_referencia if col in colunas_disponiveis]\n",
    "\n",
    "    if not colunas_validas:\n",
    "        print(\"‚ö†Ô∏è Nenhuma das colunas especificadas existe no DataFrame.\")\n",
    "        return\n",
    "\n",
    "    # Remove duplicatas\n",
    "    df_sem_duplicados = df.drop_duplicates(subset=colunas_validas)\n",
    "\n",
    "    # Aplica formata√ß√£o ao CNPJ, se existir\n",
    "    if 'cnpj' in df_sem_duplicados.columns:\n",
    "        df_sem_duplicados['cnpj'] = df_sem_duplicados['cnpj'].apply(formatar_cnpj)\n",
    "\n",
    "    # Salva o DataFrame resultante\n",
    "    df_sem_duplicados.to_excel(arquivo_saida, index=False)\n",
    "\n",
    "    # Feedback\n",
    "    total_antes = len(df)\n",
    "    total_depois = len(df_sem_duplicados)\n",
    "    print(f'‚úÖ Remo√ß√£o conclu√≠da. {total_antes - total_depois} duplicatas removidas.')\n",
    "    print(f'üìÅ Arquivo salvo em: {arquivo_saida}')\n",
    "\n",
    "\n",
    "# ==== USO ====\n",
    "\n",
    "arquivo_entrada = r'resultados_parciais838.xlsx'\n",
    "arquivo_saida = r'resposta_resultados_parciais838.xlsx'\n",
    "\n",
    "# Lista de colunas desejadas\n",
    "colunas_desejadas = ['cnpj', 'nome', 'razao_social', 'uf', 'cidade', 'email', 'link', 'cnae_desc', 'status']\n",
    "\n",
    "# Executa\n",
    "tratar_arquivo_excel(arquivo_entrada, arquivo_saida, colunas_desejadas)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
